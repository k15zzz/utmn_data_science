{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Ниже представлен простой код для классификации новостей на два класса (НАСТОЯЩИЕ и ФЕЙКИ). В качестве исходных данных используется [набор данных](https://drive.google.com/file/d/1mcG7uAcft_uoX6Asj-UgsnNQMoIg2wMw/view?usp=drive_link). Набор данных сделан на основе части [датасета](https://github.com/lutzhamel/fake-news) путем перевода первых 3000 символов с анлгийского на русский.\n",
        "\n",
        "Исправьте код, добавив строчки, которых не хватает."
      ],
      "metadata": {
        "id": "bTdYmRHyv7M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Загрузка данных и предобработка\n",
        "data = pd.read_csv('fakenews.csv')\n",
        "texts = data['Текст'].values\n",
        "labels = data['label'].values\n",
        "\n",
        "# Преобразование меток в числовой формат\n",
        "label_map = {'FAKE': 0, 'REAL': 1}\n",
        "labels = np.array([label_map[label] for label in labels])"
      ],
      "metadata": {
        "id": "p1618HuRuHGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84M39XfPuAgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc0e629c-1b0c-40e4-f1c5-1868a5e67e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Преобразование текстов в числовые векторы с помощью TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # Максимум 5000 признаков\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Обучение модели SVM\n",
        "svm_classifier = SVC(kernel='linear', C=1.0)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Оценка качества модели\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "report = classification_report(y_test, y_pred, target_names=['FAKE', 'REAL'])\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZeXASPmubHJ",
        "outputId": "6ca4a7c9-b21d-43c5-bcda-b4f043f42d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.851063829787234\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        FAKE       0.82      0.86      0.84        64\n",
            "        REAL       0.88      0.84      0.86        77\n",
            "\n",
            "    accuracy                           0.85       141\n",
            "   macro avg       0.85      0.85      0.85       141\n",
            "weighted avg       0.85      0.85      0.85       141\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Выберем один из текстов из тестовой выборки для предсказания\n",
        "test_text = X_test[0]\n",
        "\n",
        "print(X_test[0])\n",
        "\n",
        "# Предсказание для выбранного текста\n",
        "prediction = svm_classifier.predict(test_text)\n",
        "\n",
        "# Преобразуем обратно числовую метку в текстовый класс\n",
        "class_mapping = {0: 'FAKE', 1: 'REAL'}\n",
        "predicted_class = class_mapping[prediction[0]]\n",
        "\n",
        "print(\"Предсказанный класс для тестового текста:\")\n",
        "print(predicted_class)\n",
        "print('Настоящее значение класса для тестового текста:')\n",
        "print(class_mapping[y_test[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBup_-lLu_vn",
        "outputId": "0d874f0b-9658-43fa-9bff-296fc7fc1c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 134)\t0.07216964783121545\n",
            "  (0, 169)\t0.05020744575479496\n",
            "  (0, 180)\t0.043448262815671206\n",
            "  (0, 212)\t0.0776280362299774\n",
            "  (0, 318)\t0.05467864546019632\n",
            "  (0, 336)\t0.07375524802847401\n",
            "  (0, 376)\t0.023928164632630148\n",
            "  (0, 429)\t0.051594373426216526\n",
            "  (0, 432)\t0.03402881021248617\n",
            "  (0, 452)\t0.06889854313033165\n",
            "  (0, 453)\t0.026942523926395966\n",
            "  (0, 487)\t0.04963450642918136\n",
            "  (0, 527)\t0.07375524802847401\n",
            "  (0, 564)\t0.06946821045922363\n",
            "  (0, 565)\t0.05111534312334925\n",
            "  (0, 619)\t0.05169001858688397\n",
            "  (0, 637)\t0.07375524802847401\n",
            "  (0, 680)\t0.05738008283218814\n",
            "  (0, 697)\t0.05111534312334925\n",
            "  (0, 710)\t0.04554827448325314\n",
            "  (0, 715)\t0.03787230124854866\n",
            "  (0, 723)\t0.07551149208494237\n",
            "  (0, 737)\t0.04073073214563982\n",
            "  (0, 753)\t0.07075128012249306\n",
            "  (0, 755)\t0.044364401410198734\n",
            "  :\t:\n",
            "  (0, 4477)\t0.03394110930161461\n",
            "  (0, 4483)\t0.07625764415651265\n",
            "  (0, 4493)\t0.05684913888441167\n",
            "  (0, 4494)\t0.04377728546878244\n",
            "  (0, 4497)\t0.0480489062319228\n",
            "  (0, 4501)\t0.06946821045922363\n",
            "  (0, 4532)\t0.05388653216541473\n",
            "  (0, 4550)\t0.0614201035222277\n",
            "  (0, 4613)\t0.07075128012249306\n",
            "  (0, 4654)\t0.09763675042302693\n",
            "  (0, 4659)\t0.0652928917237311\n",
            "  (0, 4691)\t0.07216964783121545\n",
            "  (0, 4701)\t0.0595386223550603\n",
            "  (0, 4771)\t0.03601629225966562\n",
            "  (0, 4789)\t0.05738008283218814\n",
            "  (0, 4818)\t0.07375524802847401\n",
            "  (0, 4843)\t0.034117086215405865\n",
            "  (0, 4854)\t0.045553000214147744\n",
            "  (0, 4879)\t0.23288804011793177\n",
            "  (0, 4880)\t0.10458387635925466\n",
            "  (0, 4917)\t0.04380727188347428\n",
            "  (0, 4960)\t0.08185435804701345\n",
            "  (0, 4961)\t0.028957203222121412\n",
            "  (0, 4962)\t0.030832648952197415\n",
            "  (0, 4983)\t0.027364897150648534\n",
            "Предсказанный класс для тестового текста:\n",
            "REAL\n",
            "Настоящее значение класса для тестового текста:\n",
            "REAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В коде выше использованы переводы новостей. В наборе данных содержатся также исходные тексты новостей на анлийском. Сделайте аналогичную модель для текстов на английском. Какая модель дает более высокую точность?"
      ],
      "metadata": {
        "id": "HVnUbO0ExdCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных и предобработка\n",
        "data = pd.read_csv('fakenews.csv')\n",
        "\n",
        "texts = data['text'].values  # Изменено на 'text'\n",
        "labels = data['label'].values\n",
        "\n",
        "# Преобразование меток в числовой формат\n",
        "label_map = {'FAKE': 0, 'REAL': 1}\n",
        "labels = np.array([label_map[label] for label in labels])\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Преобразование текстов в числовые векторы с помощью TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # Максимум 5000 признаков\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Обучение модели SVM\n",
        "svm_classifier = SVC(kernel='linear', C=1.0)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Оценка качества модели\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "report = classification_report(y_test, y_pred, target_names=['FAKE', 'REAL'])\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Выберем один из текстов из тестовой выборки для предсказания\n",
        "test_text = X_test[0]\n",
        "\n",
        "# Предсказание для выбранного текста\n",
        "prediction = svm_classifier.predict(test_text)\n",
        "\n",
        "# Преобразуем обратно числовую метку в текстовый класс\n",
        "class_mapping = {0: 'FAKE', 1: 'REAL'}\n",
        "predicted_class = class_mapping[prediction[0]]\n",
        "\n",
        "print(\"Predicted class for the test text:\")\n",
        "print(predicted_class)\n",
        "print('Actual class for the test text:')\n",
        "print(class_mapping[y_test[0]])"
      ],
      "metadata": {
        "id": "CgW6exVBvHWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2331e58a-bb82-480a-b85a-7e191d59d613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8723404255319149\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        FAKE       0.84      0.89      0.86        64\n",
            "        REAL       0.90      0.86      0.88        77\n",
            "\n",
            "    accuracy                           0.87       141\n",
            "   macro avg       0.87      0.87      0.87       141\n",
            "weighted avg       0.87      0.87      0.87       141\n",
            "\n",
            "Predicted class for the test text:\n",
            "REAL\n",
            "Actual class for the test text:\n",
            "REAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Исходя из полученных результатов, модель, обученная на текстах на английском языке, показала немного более высокую точность (87,2%) по сравнению с моделью, обученной на текстах на русском языке (85,1%). Это может быть связано с тем, что исходные тексты были на английском языке, и при переводе на русский язык могли потеряться некоторые нюансы, которые помогают в классификации.\n",
        "\n",
        "Тем не менее, обе модели показали довольно высокую точность, что говорит о том, что они обе эффективны в классификации новостей на \"настоящие\" и \"фейковые\".\n",
        "\n",
        "Важно отметить, что точность модели может зависеть от многих факторов, включая качество исходных данных, выбор признаков, параметры модели и т.д. Поэтому всегда стоит проводить тщательную предварительную обработку данных и тонкую настройку модели для достижения наилучших результатов."
      ],
      "metadata": {
        "id": "vcajdax24Ulu"
      }
    }
  ]
}